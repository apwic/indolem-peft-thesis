\section{Pengembangan Ulang Kakas IndoLEM}
\label{sec:pengembangan-kakas}

Pengembangan ulang IndoLEM ini diperlukan untuk memperbarui dan memperbaiki infrastruktur dari kakas tersebut. Pengembangan ini dilakukan pada lingkungan lokal pribadi. Sedangkan, untuk keperluan eksperimen, dilakukan pada lingkungan \textit{cloud} seperti yang sudah disebutkan pada subbab \ref{sec:lingkungan-eksperimen}.

\subsection{Persiapan Lingkungan Pengembangan}

Implementasi diawali dengan menyiapkan lingkungan pengembangan. Untuk menyiapkan lingkungan pengembangan, dilakukan instalasi terhadap perangkat lunak dan pustaka yang dibutuhkan. \textit{File requirements.txt} pustaka yang perlu dilakukan instalasi, seperti yang  bisa dilihat pada tabel \ref{table:requirements}

\begin{table}[h]
    \caption{\textit{Requirements.txt}}
    \label{table:requirements}
    \begin{lstlisting}[language=bash]
    accelerate
    adapters==0.2.2
    datasets
    evaluate
    huggingface-hub
    numpy
    pandas
    scikit-learn
    seqeval
    torch
    transformers==4.40.*
    wandb
    nltk
    rouge_score
    indobenchmark-toolkit
    \end{lstlisting}
\end{table}

Untuk memudahkan pengembangan, perlu dibuat \textit{virtual environment} untuk mengenkapsulasi pustaka yang dipakai. \textit{Virtual environment} bisa dibuat dengan menggunakan Conda atau pustaka virtualenv. Untuk tugas akhir ini, digunakan Conda. \textit{Command} yang digunakan dapat dilihat pada tabel \ref{table:command-virtualenv}.

\begin{table}[h]
    \caption{\textit{Command virtual environment}}
    \label{table:command-virtualenv}
    \begin{lstlisting}[language=bash]
    # Membuat virtual environment
    conda create env -n indolem python=3.11
    # Menjalankan virtual environment
    conda activate indolem
    # Melakukan instalasi pustaka 
    pip install -r requirements.txt
    \end{lstlisting}
\end{table}

\textit{Command} tersebut  membuat \textit{virtual environment}, mengakitfkannya, dan melakukan instalasi pada versi Python dan pustaka yang dibutuhkan.

\subsection{\textit{Parsing} Argumen}
\label{sec:parse-arg}

\textit{Parsing} argumen dilakukan dengan menggunakan modul HfArgumentParser dari pustaka Transformers. Modul ini digunakan untuk memudahkan \textit{Parsing} argumen karena argumen yang dipakai untuk model, pelatihan, dan evaluasi sudah diimplementasikan dari modul tersebut. Untuk argumen tambahan yang spesifik pada suatu tugas evaluasi perlu dilakukan penambahan secara manual. Sebagai contoh pada tugas evaluasi NER terdapat argumen \texttt{return\_entity\_level\_metrics} yaitu menggunakan metrik evaluasi untuk level entitasnya.

\begin{table}[h]
    \caption{Kode HfArgumentParser}
    \label{table:hfargumentparser}
    \begin{lstlisting}[language=python]
    parser = HfArgumentParser(
        [
            ModelArguments,
            DataTrainingArguments,
            TrainingArguments,
            AdapterArguments,
            WandbArguments,
        ]
    )
    \end{lstlisting}
\end{table}

Berdasarkan tabel \ref{table:hfargumentparser} terdapat 5 jenis argumen, yaitu model, \textit{data training}, pelatihan, \textit{adapter}, dan wandb. Argumen model digunakan untuk pemuatan model. Argumen \textit{data training} digunakan untuk pemuatan \textit{file} (latih, evaluasi, dan uji), \textit{padding}, maksimum sampel, maksimum sekuens, dan lain sebagainya yang berhubungan dengan \textit{dataset}. Lalu, argumen pelatihan merupakan \textit{hyperparameter} yang digunakan pada proses pelatihan seperti \textit{learning rate, epoch, batch size}, dan lain sebagainya. Selanjutnya, argumen \textit{adapter} berfungsi sebagai konfigurasi untuk jenis metode PEFT beserta \textit{hyperparameter} yang digunakannya. Terakhir, argumen wandb yang digunakan untuk konfigurasi sinkronisasi pada hasil evaluasi ke \textit{cloud}.

\subsection{Praproses \textit{Dataset}}
\label{sec:praproses}

Praproses \textit{dataset} diperlukan agar model dapat memproses \textit{dataset} dengan konteks yang sesuai. Konteks yang dimaksud adalah model dapat memahami \textit{metadata} dari \textit{dataset}, sehingga mampu mengetahui setiap bagian data yang merupakan bagian dari teks atau label. Praproses \textit{dataset} ini berbeda untuk setiap tugas evaluasi karena karakteristik dari tugas evaluasinya yang berbeda juga.

\subsubsection{Praproses Data NER}

Tugas evaluasi NER merupakan jenis tugas \textit{classification} pada level token yang berarti setiap token  diklasifikasikan dengan label tertentu. Pada IndoLEM, untuk tugas evaluasi NER terdapat dua jenis \textit{dataset}, yaitu NERUI dan NERUGM. Kedua \textit{dataset} tersebut mempunyai label yang berbeda berikut merupakan label pada setiap \textit{dataset}-nya dapat dilihat pada tabel \ref{table:label-ner}.

Label tersebut diperlukan untuk melakukan \textit{mapping} antara id dengan labelnya yang  digunakan pada konfigurasi model. \textit{Padding} juga dilakukan berdasarkan panjang sekuens maksimum yang didefinisikan melaluai argumen \textit{data training}. Selanjutnya, tokenisasi  dilakukan terhadap \textit{dataset} tersebut. Tokenisasi dilakukan dengan menggunakan modul Tokenizer pada pustaka Transformers. Fungsi tokenisasi mengabaikan token spesial [CLS] dan [SEP] yang muncul dari hasil tokenisasi model berbasi BERT. Token spesial tersebut diubah menjadi -100 agar bisa diabaikan dari perhitungan metrik evaluasinya. Sehingga, hanya token yang berkorespondensi terhadap sebuah label saja yang dapat dievaluasi.

\subsubsection{Praproses Data \textit{Sentiment Analysis}}

Tugas evaluasi \textit{sentiment analysis} merupakan jenis tugas \textit{classification} yang sama seperti NER, hanya perbedaannya pada level klasifikasi yang digunakan. Jika pada NER klasifikasi dilakukan pada level token, pada \textit{sentiment analysis} klasifikasi dilakukan pada level teks yang merupakan gabungan dari beberapa token. \textit{Dataset} dari \textit{sentiment analysis} berupa \textit{file} CSV yang berisi dari dua kolom yaitu \textit{sentence} dan \textit{labels}. Kolom \textit{sentence} merupakan teks yang mengandung sentimen tertentu. Sementara kolom \textit{labels} menandakan sentimen dari teks tersebut, dengan nilai 0 berupa sentimen negatif dan  nilai 1 berupa sentimen positif.

Pada tugas evaluasi \textit{sentiment analysis}, diperlukan \textit{mapping} antara label dengan idnya, sehingga model mampu mengetahui label yang dilatih. Fungsi tokenisasi \textit{sentiment analysis} menggunakan modul Tokenizer dari pustaka Transformers. Pada fungsi tersebut terdapat \textit{sentence1\_key} dan juga \textit{sentence2\_key}, yang berguna apabila terdapat dua kolom teks pada \textit{dataset}. Akan tetapi, pada IndoLEM \textit{dataset sentiment analysis} hanya mempunyai satu kolom teks. Sehingga, \textit{sentence2\_key} tidak digunakan. 

\subsubsection{Praproses Data \textit{Summarization}}

Tugas evaluasi \textit{summarization} merupakan jenis tugas \textit{generation} yang berbeda dengan jenis tugas \textit{classification}. Tugas \textit{generation} memerlukan generasi teks untuk dapat dilakukan evaluasi, pada konteks ini yaitu membuat ringkasan dari teks. \textit{Dataset} yang digunakan pada IndoLEM untuk tugas evaluasi \textit{summarization} adalah \textit{dataset} IndoSUM. \textit{Dataset} ini berisi \textit{file} dengan format JSONL dengan masing-masing objek dapat dilihat pada tabel \ref{table:label-summarization}.

Dari data yang dapat dilihat pada tabel \ref{table:label-summarization}, terdapat 7 objek  pada \textit{dataset}. Namun, pada tugas evaluasi ini hanya  digunakan dua objek yaitu \textit{paragraphs} dan \textit{summary} karena tugas \textit{summarization} membutuhkan teks asli sebelum diringkas dan hasil ringkasannya. Objek yang lain selain dua yang digunakan bisa diabaikan saja. \textit{Dataset} ini perlu dipraproses terlebih dahulu menggunakan fungsi tokenisasi.

Tokenisasi dilakukan dengan mengolah objek \textit{paragraphs} menjadi \textit{list} dari teks. Setiap paragraf terdiri dari beberapa kalimat, dan setiap kalimat terdiri dari beberapa teks. Untuk \textit{text\_column} yang merupakan objek \textit{paragraphs}  diolah menjadi \textit{list} dari teks. Hal yang sama berlaku juga untuk \textit{summary\_column}, hanya saja objek ini merupakan \textit{summary} yang berisi kalimat. Selain itu, tugas evaluasi \textit{summarization} memiliki \textit{prefix} yang berguna pada beberapa model tertentu. Tokenisasi juga menggunakan modul \textit{tokenizer} dari pustaka Transformers.

\subsection{Pemuatan Konfigurasi Model}

Untuk dapat melakukan pelatihan dan evaluasi terhadap model, model perlu dimuat terlebih dahulu. Pemuatan model ini menggunakan konfigurasi yang dimuat dari \textit{parsing} argumen pada subbab \ref{sec:parse-arg}. Argumen model  dimuat ke dalam model sehingga model bisa dipakai. Model  dimuat dengan menggunakan modul yang relevan dari pustaka Transformers.

\begin{table}[h]
    \caption{Kode pemuatan model \textit{summarization}}
    \label{table:kode-model-summ}
    \begin{lstlisting}[language=python]
    model = AutoModelForSeq2SeqLM.from_pretrained(
        model_args.model_name_or_path,
        from_tf=bool(".ckpt" in model_args.model_name_or_path),
        config=config,
        cache_dir=model_args.cache_dir,
        revision=model_args.model_revision,
        token=True if model_args.token else None,
    )
    \end{lstlisting}
\end{table}

Pada tabel \ref{table:kode-model-summ}, dimuat model AutoModelForSeq2SeqLM yaitu model \textit{sequence to sequence} yang merupakan model \textit{encoder decoder}. Modul AutoModel ini  menghasilkan model berdasarkan dari konfigurasi \textit{model\_args} yang dimasukkan pada modul tersebut. Untuk tugas evaluasi \textit{summarization} yang menggunakan model IndoT5  menghasilkan model tersebut juga. Berbeda untuk tugas \textit{classification}, cukup dengan menyatakan AutoModel saja sudah cukup untuk menghasilkan model yang sesuai. Pada konteks ini, model yang digunakan untuk NER dan \textit{sentiment analysis} adalah IndoBERT yang berbasis BERT.

\subsection{Perhitungan Metrik Evaluasi}
\label{sec:metriks-evaluasi}

Metrik evaluasi yang digunakan pada setiap tugas evaluasi berbeda-beda. Metrik yang digunakan untuk tugas \textit{classification} adalah \textit{accuracy} dan F1 \textit{score}. Sedangkan, pada tugas \textit{generation} adalah ROUGE \textit{score}. Perhitungan metrik evaluasi ini dilakukan saat proses evaluasi dengan menggunakan fungsi \textit{compute\_metrics}.

\begin{table}[h]
    \caption{Fungsi \textit{compute\_metrics}}
    \label{table:compute-metrics}
    \begin{lstlisting}[language=python]
    def compute_metrics(p):
        logits, labels = p
        predictions = np.argmax(logits, axis=1)

        return {
            "accuracy": accuracy_score(labels, predictions),
            "precision": precision_score(labels, predictions, average="macro"),
            "recall": recall_score(labels, predictions, average="macro"),
            "f1": f1_score(labels, predictions, average="macro"),
        }
    \end{lstlisting}
\end{table}

Pada tabel \ref{table:compute-metrics}, fungsi perhitungan metrik evaluasinya merupakan fungsi yang dipakai untuk tugas \textit{classification}. Fungsi tersebut memanfaatkan modul seqeval untuk melakukan perhitungan setiap metrik. Terdapat perbedaan pada fungsi yang dipakai pada tugas \textit{classification}, NER menggunakan \textit{entity\_level\_metrics} yang berarti perhitungan evaluasinya berdasarkan pada entitasnya yang berbeda dengan \textit{sentiment analysis}. Untuk tugas \textit{generation} yaitu \textit{summarization} menggunakan ROUGE \textit{score}.

\subsection{Pemuatan Trainer untuk Pelatihan dan Evaluasi Model}

Untuk pelatihan dan evaluasi model dibutuhkan standardisasi agar kode yang digunakan pada setiap tugas tidak berbeda. Modul Trainer dari pustaka Transformers digunakan untuk pelatihan dan evaluasi model. Setiap komponen yang sudah disebutkan sebelumnya  dimuat pada modul Trainer. Setiap tugas evaluasi  menggunakan implementasi yang sama yang bisa dilihat pada tabel \ref{table:kode-trainer}.

\begin{table}[h]
    \caption{Kode implementasi Trainer}
    \label{table:kode-trainer}
    \begin{lstlisting}[language=python]
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset if training_args.do_train else None,
        eval_dataset=eval_dataset if training_args.do_eval else None,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
    )

    trainer.train(resume_from_checkpoint=checkpoint)
    trainer.evaluate()
    \end{lstlisting}
\end{table}

Kode implementasi Trainer pada tabel \ref{table:kode-trainer} memuat modul Trainer dan memanggil metode \textit{train} dan \textit{evaluate} untuk melakukan pelatihan dan evaluasi. Modul Trainer membutuhkan beberapa argumen yang dimuat. Argumen tersebut dimuat dari komponen-komponen yang sudah disebutkan pada subbab sebelumnya. Argumen untuk pelatihan, dan model didapat dari hasil \textit{parsing} argumen pada \ref{sec:parse-arg}. Untuk \textit{tokenizer} dan \textit{dataset} pelatihan dan evaluasi dimuat dari hasil praproses data pada \ref{sec:praproses}. Lalu, untuk \textit{compute\_metrics} fungsinya dimuat dari metrik evaluasi pada \ref{sec:metriks-evaluasi}. 
