\section{Rancangan Solusi}
\label{sec:rancangan-solusi}

Dibangun sebuah rancangan solusi berupa skenario pengujian yang dilakukan dalam penelitian tugas akhir, yang dapat dilihat pada Gambar \ref{fig:rancangan-solusi}. Berdasarkan Gambar \ref{fig:rancangan-solusi}, tidak ditambahkan dataset baru, melainkan menggunakan dataset yang sudah disediakan pada IndoLEM. Teknik PEFT yang digunakan adalah LoRA (\textit{Low-Rank Adaptation}), \textit{Prefix-Tuning}, dan \textit{Bottleneck Adapter}. Hasil pengujian berupa kinerja dari teknik PEFT serta penggunaan sumber daya dari setiap eksperimen.

\begin{figure}[ht]
    \centering
    \includegraphics[height=0.5\textheight]{chapter-3/rancangan_solusi.png}
    \caption{Rancangan Solusi}
    \label{fig:rancangan-solusi}
\end{figure}

Sebelum bisa dilakukan pelatihan dan evaluasi model, kakas IndoLEM perlu dilakukan pengembangan ulang serta perlu dikembangkan metode PEFT pada kakas IndoLEM. Pengembangan ulang ini dilakukan agar pengembangan metode PEFT bisa dilakukan. Pengembangan ulang kakas IndoLEM akan menggunakan beberapa pustaka, salah satunya adalah Transformers dan Torch. Pustaka Transformers diperlukan untuk melakukan pemuatan model, praproses data, dan penggunaan Trainer untuk standardisasi. Lalu, pustaka Torch digunakan untuk menggunakan CUDA yang memanfaatkan GPU untuk melatih model. Selain itu, pustaka Wandb dan Huggingface juga akan dipakai untuk melakukan sinkronisasi pada \textit{cloud}. Dengan sinkronisasi ini, hasil pelatihan model dan hasil evaluasi dapat dilihat pada situsnya yang akan memudahkan proses eksperimen. 

Pengembangan metode PEFT pada kakas IndoLEM akan menggunakan pustaka Adapters. Model yang dimuat oleh pustaka Transformers perlu diinisiasi oleh pustaka Adapters untuk dapat berjalan menggunakan metode PEFT. Untuk dapat menjalankan proses pelatihan dengan metode PEFT, perlu menggunakan Trainer yang berasal dari pustaka Adapters yaitu AdapterTrainer yang akan melakukan \textit{freeze} pada parameter model dan akan menggunakan parameter yang sesuai dengan metode PEFT-nya tersebut.

Sesuai dengan banyaknya tugas evaluasi yang diimplementasikan, jumlah dari \textit{dataset} juga sebanyak tugas evaluasi tersebut, yaitu \nlptask. Setiap \textit{dataset} akan dilakukan 5-\textit{fold cross validation} yang membagi setiap dataset menjadi 5 bagian \textit{dataset} validasi yang berbeda. Metode \textit{cross validation} ini sudah dilakukan pada kakas IndoLEM, sehingga \textit{dataset} sudah terbagi menjadi 5-\textit{fold}. Untuk setiap \textit{fold}-nya, \textit{dataset} akan dilakukan praproses data, pelatihan model, dan evaluasi kinerja. Praproses data ini dilakukan dengan melakukan \textit{padding}, tokenisasi, dan juga mengatur \textit{mapping} dengan labelnya. 

Untuk proses pelatihan model akan dibagi menjadi dua, yaitu dengan menggunakan \textit{fine-tuning} tradisional dan menggunakan metode PEFT. Pelatihan model akan dilakukan pada lingkungan pelatihan yang sesuai yaitu pada lingkungkan \textit{cloud} yang menggunakan GPU khusus untuk pelatihan model. Pelatihan dengan \textit{fine-tuning} tradisional akan mengikuti \textit{hyperparameter} pada penelitian terkaitnya. Sedangkan, untuk metode PEFT akan dilakukan \textit{hyperparameter tuning} untuk metode PEFT-nya.

Selanjutnya, untuk setiap hasil pelatihan model akan dilakukan evaluasi pada dengan menggunakan \textit{dataset} validasi-nya. Metriks evaluasi yang akan digunakan tergantung pada tugas evaluasinya. Tugas evaluasi \textit{classification} yaitu NER dan \textit{sentiment analyisis} akan menggunakan \textit{accuracy} dan F1 \textit{score}. Sedangkan, tugas evaluasi \textit{generation} yaitu \textit{summarization} akan menggunakan ROGUE \textit{score}.

