\section{\textit{Fine-Tuning}}

\textit{Transfer Learning} merupakan salah satu pendekatan kunci dalam pembelajaran mesin yang memanfaatkan model yang telah dilatih pada tugas tertentu sebagai dasar untuk melatih model pada tugas lain. Ide dasar di balik \textit{transfer learning} adalah bahwa, jika model telah mempelajari fitur-fitur tertentu dari satu tugas, fitur-fitur tersebut dapat digunakan sebagai informasi awal yang berguna untuk tugas lain.

Sebagai contoh, model yang telah dilatih untuk mengenali objek dalam gambar dapat memanfaatkan pengetahuannya tentang fitur visual, seperti tepi atau tekstur, saat dilatih untuk tugas pengenalan wajah. Meskipun tugas awal (mengenali objek) dan tugas kedua (pengenalan wajah) berbeda, ada sejumlah fitur visual yang relevan untuk kedua tugas tersebut.

Dalam konteks pemrosesan bahasa alami (NLP), \textit{transfer learning} sering digunakan untuk memanfaatkan \textit{Pre-Trained Model} (PLM) yang telah dilatih pada korpus teks besar untuk tugas-tugas spesifik seperti \textit{sentiment analysis} atau \textit{named entity recognition}. Dengan memulai dari model yang telah memiliki pemahaman dasar tentang struktur dan semantik bahasa, proses \textit{training} untuk tugas spesifik menjadi lebih cepat dan seringkali menghasilkan model yang lebih akurat dibandingkan dengan melatih model dari awal.

Keuntungan lain dari \textit{transfer learning} adalah efisiensi komputasi. Melatih model pembelajaran mesin dari awal, terutama model dengan banyak parameter, memerlukan sumber daya komputasi yang signifikan. Dengan menggunakan model yang telah dilatih sebagai titik awal, dapat menghemat waktu dan sumber daya komputasi, sambil mempertahankan atau bahkan meningkatkan kinerja model.

Salah satu metode yang sering digunakan untuk \textit{transfer-learning} adalah \textit{fine-tuning}. \textit{Pre-trained model} yang sebelumnya sudah dilatih pada data latih yang besar, dapat dilatih lebih lanjut untuk tugas NLP spesifik lainnya. Proses ini memerlukan \textit{dataset} tambahan, sehingga model dapat mendapatkan pengetahuan tambahan yang spesifik diperlukan terkait tugas NLP tersebut.

Proses \textit{fine-tuning} melanjutkan fase \textit{training} dengan \textit{dataset} tambahan yang diberikan kepada model. Sebelumnya, model mempunyai parameternya sendiri yang berasal dari proses \textit{pre-training}. \textit{Fine-tuning} membolehkan perubahan pada semua parameter model untuk menyesuaikan pada \textit{dataset} tambahan. Agar pengetahuan yang sebelumnya dimiliki oleh model tidak hilang ketika proses pengubahan parameter, \textit{learning rate} bernilai kecil bisa digunakan pada proses ini.

\textit{Fine-tuning} merupakan metode \textit{transfer learning} yang efisien ketika dilatih pada tugas spesifik dengan \textit{dataset} yang relatif kecil. Metode ini mengurangi kebutuhan  sumber daya komputasi dan waktu yang besar, yang biasanya dibutuhkan untuk melakukan \textit{training} model dari awal.
