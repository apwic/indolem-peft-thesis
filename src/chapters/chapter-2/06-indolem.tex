\section{Kakas Evaluasi IndoLEM}
% TODO: jelasin proses eksperimen saat ini, dan datasetnya juga 
Dari banyaknya kakas evaluasi NLU yang tersedia, seperti GLUE, kebanyakan dari kakas tersebut hanya berfokus pada bahasa Inggris \parencite{indolem}. IndoLEM muncul untuk mengisi kekosongan tersebut dengan menyediakan kakas evaluasi yang spesifik untuk bahasa Indonesia \parencite{indolem}. IndoLEM itu sendiri merupakan singkatan dari \textit{Indonesian Language Evaluation Montage} (IndoLEM), dengan nama tersebut terinspirasi dari GLUE yang diterjemahkan secara langsung menjadi "LEM" \parencite{indolem}. IndoLEM menstandarisasi pembagian data dan metriks evaluasi yang digunakan, sehingga akan lebih mudah untuk direka ulang sebagai kakas evaluasi \parencite{indolem}.

Tugas evaluasi yang terdapat pada kakas IndoLEM dibagi menjadi tiga, yaitu \textit{sequence labelling}, \textit{semantic}, dan \textit{coherency}. Untuk \textit{sequence labelling} terdapat tiga tugas, yaitu \textit{part-of-speech} (POS) \textit{tagging}, \textit{named entity recognition} (NER), dan \textit{dependency parsing}. Lalu, untuk \textit{semantic} terdapat dua tugas, yaitu \textit{sentiment analysis} dan \textit{summarization}. Terakhir, untuk \textit{coherency} terdapat dua tugas, yaitu \textit{next tweet prediction} dan \textit{tweet ordering}. Tugas yang akan dibahas pada tugas akhir ini hanya tiga, yaitu NER, \textit{sentiment anaylsis}, dan \textit{summarization}.

\subsection{NER pada IndoLEM}

\textit{Dataset} NER yang digunakan pada IndoLEM ada dua yaitu NER UI dan NER UGM \parencite{indolem}. Yang pertama, NER UI, terdiri dari 2.125 kalimat yang didapatkan dari anotasi yang dilakukan oleh Universitas Indonesia (UI) \parencite{indolem}. NER UGM terdiri dari 2.343 kalimat yang didapatkan dari artikel berita. NER UGM dibuat oleh Universitas Gajah Mada (UGM) \parencite{indolem}. Label pada kedua \textit{dataset} tersebut dapat dilihat pada tabel \ref{table:label-ner}. Entitas dari NER UI terdiri dari \textit{location, organization}, dan \textit{person}, sedangkan NER UGM terdiri dari 3 entitas yang sama dari NER UI ditambah \textit{quantity} dan \textit{time}.

\begin{table}[h]
    \vspace{0.25cm}
    \centering
    \caption{Label \textit{dataset} NER}
    \label{table:label-ner}
    \begin{tabular}{l|l}
        \toprule
        \multicolumn{1}{c}{\textbf{NER UI}} & \multicolumn{1}{c}{\textbf{NER UGM}} \\
        \midrule
        B-LOCATION & B-LOCATION \\
        B-ORGANIZATION & B-ORGANIZATION \\
        B-PERSON & B-PERSON \\
        - & B-QUANTITY \\
        - & B-TIME \\
        I-LOCATION & I-LOCATION \\
        I-ORGANIZATION & I-ORGANIZATION \\
        I-PERSON & I-PERSON \\
        - & I-QUANTITY \\
        - & I-TIME \\
        O & O \\
        \bottomrule
    \end{tabular}
\end{table}

Kedua \textit{dataset} dilakukan 5-\textit{fold cross validation} Kedua \textit{dataset} dilakukan 5-\textit{fold cross validation} dengan menggunakan $10\%$ sebagai validasi data \parencite{indolem}. Evaluasi yang dilakukan untuk kedua \textit{dataset} adalah \textit{entity-level} F1 yang dilakukan pada data tes. Selain itu, \citeauthor{indolem} melakukan evaluasi terhadap kedua \textit{dataset} tersebut dan ditemukan bahwa kualitas NER UI lebih baik dibandingkan NER UGM, dengan kesalahan pada NER UGM sebagian besar karena rendahnya nilai \textit{recall}, yaitu memberikan label O pada entitas bernama \parencite{indolem}.

\begin{table}[h]
    \vspace{0.25cm}
    \centering
    \caption{Hasil evaluasi NER pada IndoLEM}
    \label{table:indolem-ner-result}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Method} & \textbf{NER UGM F1} & \textbf{NER UI F1} \\
        \midrule
        BiLSTM-CRF & 70.9 & 82.2 \\
        mBERT & 71.6 & 82.2 \\
        MALAYBERT & 73.2 & 87.4 \\
        INDOBERT & \textbf{74.9} & \textbf{90.1} \\
        \bottomrule 
    \end{tabular}
\end{table}

Hasil evaluasi dapat dilihat pada tabel \ref{table:indolem-ner-result}, dengan \textit{baseline} merupakan BiLSTM dengan 300d \texttt{fastText} \textit{embedding} berbahasa Indonesia \parencite{indolem}. Untuk model BERT dilakukan metode \textit{fine-tuning} dengan nilai $learning\_rate$ yaitu $5e-5$ dan dilakukan dengan 100 $epoch$. IndoBERT mendapatkan nilai terbaik untuk kedua \textit{dataset}.

\subsection{\textit{Sentiment Analysis} pada IndoLEM}

\textit{Dataset sentiment analysis} pada IndoLEM berasal dari Twitter dan ulasan hotel \parencite{indolem}. Data ulasan hotel berisi sentimen pada level aspek, dengan setiap ulasan mempunyai beberapa polaritas pada aspek yang berbeda \parencite{indolem}. Dilakukan perhitungan proporsi antara aspek positif dan negatif, dan label diberikan kepada apsek yang merupakan mayoritas \parencite{indolem}. \textit{Sentiment analysis} yang dilakukan pada IndoLEM menggunakan klasifikasi biner, label 0 berarti negatif dan sebaliknya. Pembagian \textit{dataset} adalah 3638 untuk data pelatihan, 399 untuk data evaluasi, dan 1011 untuk data tes \parencite{indolem}. 

\begin{table}[h]
    \vspace{0.25cm}
    \centering
    \caption{Hasil evaluasi \textit{sentiment analysis} pada IndoLEM}
    \label{table:indolem-sentiment-result}
    \begin{tabular}{lc}
        \toprule
        \textbf{Method} & \textbf{Sentiment Analysis (F1)} \\
        \midrule
        Naive Bayes & 70.95 \\
        Logistic Regression & 72.14 \\
        BiLSTM w/ \texttt{fastText} & 71.62 \\
        mBERT & 76.58 \\
        MALAYBERT & 82.02 \\
        INDOBERT & \textbf{84.13} \\
        \bottomrule
    \end{tabular}
\end{table}

\textit{Dataset} tersebut juga dilakukan 5-\textit{fold cross validation} karena data yang tidak seimbang dan \textit{low-resource} \parencite{indolem}. Metriks evaluasi yang digunakan adalah skor F1. Evaluasi dilakukan dengan \textit{baseline} yaitu BiLSTM, Naive Bayes, dan \textit{logistic regression}. Setiap model BERT menggunakan masukan sebanyak 200 token, $learning\_rate$ dengan nilai $5e-5$, $batch\_size$ dengan nilai 30, dan $warm\_up$ sebesar $10\%$ dari total $step$. Berdasarkan tabel \ref{table:indolem-sentiment-result}, IndoBERT juga mendapatkan nilai terbaik untuk tugas evaluasi \textit{sentiment analysis}.

\subsection{\textit{Summarization} pada IndoLEM}

Tugas \textit{summarization} menggunakan \textit{dataset} yang telah tersedia yaitu IndoSUM \parencite{summarization}. IndoSUM berisi sekitar 19.000 dokumen-ringkasan \textit{dataset} \parencite{indolem}, dengan setiap dokumen mempunyai satu \textit{abstractive summary}. \citeauthor{summarization} merilis IndoSUM beserta dengan ORACLE, yaitu sekumpulan \textit{extractive summary} yang dihasilkan secara otomatis dengan memaksimalkan skor ROUGE antar kalimat pada dokumen dengan \textit{abstractive summary}-nya \parencite{indolem}.

\begin{table}[h]
    \vspace{0.25cm}
    \centering
    \caption{Hasil evaluasi \textit{summarization} pada IndoLEM}
    \label{table:indolem-summarization-result}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Method} & \textbf{R1} & \textbf{R2} & \textbf{RL} \\
        \midrule
        \textsc{Oracle} & 79.27 & 72.52 & 78.82 \\
        Kurniawan and Louvan (2018) & 17.62 & 4.70 & 15.89 \\
        Cheng and Lapata (2016) & 67.96 & 61.65 & 67.24 \\
        mBERT & 68.40 & 61.66 & 67.67 \\
        MALAYBERT & 68.44 & 61.38 & 67.71 \\
        INDOBERT & \textbf{69.93} & \textbf{62.86} & \textbf{69.21} \\
        \bottomrule
    \end{tabular}
\end{table}

\textit{Dataset} ini juga dilakukan 5-\textit{fold cross validation}. Evaluasi dilakukan dengan menggunakan dua \textit{baseline}, yaitu \citeauthor{summarization} dan \citeauthor{summarization_lstm} beserta ORACLE yang merupakan batas atas dari \textit{extractive summary}. Untuk model BERT mengikuti penelitian dari \citeauthor{summarization_bert} \parencite{indolem}. Metriks evaluasi yang digunakan adalah skor ROUGE, yaitu R1, R2, dan RL. Hasil evaluasi dapat dilihat pada tabel \ref{table:indolem-summarization-result}, dengan IndoBERT mendapatkan nilai yang terbaik juga.
