\section{Latar Belakang}
\label{sec:latar-belakang}

Pengolahan bahasa alami (\textit{Natural Language Processing}, NLP) telah menjadi salah satu bidang yang mengalami perkembangan pesat. Kemampuan untuk memahami, menginterpretasi, dan merespons bahasa manusia secara bermakna telah membuka berbagai aplikasi baru yang inovatif. Pengaplikasian bahasa alami mencakup berbagai aspek, mulai dari pemahaman teks (seperti \textit{text classification} dan \textit{sentiment analysis}), hingga generasi bahasa (seperti \textit{machine translation}).

Kemampuan bahasa dari manusia bersifat umum dan fleksible. Sebaliknya, evaluasi kemampuan pemahaman bahasa (\textit{natural language understanding}, NLU) dari NLP perlu menjalankan berbagai tugas linguistik pada berbagai domain \parencite{glue}. Untuk mengatasi masalah ini, terdapat banyak kakas dan korpora yang telah diajukan. Salah satunya adalah GLUE (\textit{General Language Understanding Evaluation}) \parencite{glue} dan SuperGLUE \parencite{superglue} untuk mengevaluasi NLU dalam bahasa Inggirs. GLUE meliputi 9 tugas evaluasi, sedangkan SuperGLUE merupakan jenis evaluasi yang lebih sulit dari GLUE yang memiliki delapan tugas evaluasi \parencite{indolem}.

Untuk evaluasi pemahaman NLP dalam bahasa Indonesia, terdapat beberapa kakas yang telah diajukan, salah satunya dalah IndoLEM \parencite{indolem}, IndoNLU \parencite{indonlu}, dan IndoNLG \parencite{indonlg}. IndoLEM merupakan kakas yang muncul dari ketiadaan kakas evaluasi NLU untuk bahasa Indonesia. IndoLEM terdiri dari 7 tugas, salah satunya adalah \textit{named entity recognition} (NER), \textit{sentiment analysis}, dan \textit{summarization} \parencite{indolem}. IndoNLU menyediakan 12 evaluasi NLU, sedangkan IndoNLG fokus terhadap evaluasi \textit{natural language generation} (NLG).

Dalam proses evaluasi NLU, model perlu dilatih pada \textit{dataset} yang tersedia pada kakas tersebut, lalu evaluasi bisa dilakukan dengan membandingkan hasil pelatihannya dengan \textit{benchmark} yang ada. Proses pelatihan ini menggunakan metode \textit{fine-tuning} \parencite{indolem}. Terdapat peluang untuk peningkatan lebih lanjut, terutama dalam hal efisiensi parameter yang digunakan dan waktu pelatihannya. Penggunaan \textit{fine-tuning} pada proses pelatihan, memerlukan sumber daya komputasi yang besar, yang tidak selalu tersedia atau praktis untuk semua pengguna. Salah satu pendekatan yang menjanjikan untuk mengatasi tantangan ini adalah penggunaan teknik \PEFT. PEFT memungkinkan model untuk menyesuaikan dengan tugas-tugas spesifik dengan mengubah jumlah parameter yang relatif kecil sehingga mempertahankan sebagian besar parameter model yang telah dilatih sebelumnya \parencite{adapter}. Teknik ini tidak hanya dapat mengurangi waktu dan biaya komputasi, tetapi juga memungkinkan penyesuaian model yang lebih cepat dan lebih fleksibel untuk aplikasi spesifik. 

Teknik \PEFT memiliki berbagai variasi, seperti LoRA (\textit{Low-Rank Adaptation}), \textit{Prefix-Tuning}, dan \textit{Bottleneck Adapter}. Penelitian yang dilakukan oleh \citeauthor{adapter} \parencite{adapter} dan \citeauthor{uvpl} \parencite{uvpl} menunjukkan bahwa dengan memperbarui kurang dari 4\% parameter, metode berbasis PEFT dapat mencapai kinerja yang sebanding dengan metode \textit{fine-tuning} penuh. Setiap teknik memiliki karakteristiknya sendiri, dan hingga saat ini, belum banyak penelitian yang secara komprehensif membandingkan kinerja antara teknik-teknik ini, terutama ketika diterapkan pada model IndoBERT. 

Tugas akhir ini akan difokuskan pada pemanfaatan berbagai teknik \PEFT pada kakas evaluasi IndoLEM dengan tujuan untuk mengimplementasikan berbagai metode PETL pada kakas evaluasi IndoLEM. Selain itu, tugas akhir ini akan membandingkan kinerja berbagai teknik \PEFT dengan metode \textit{fine-tuning} tradisional untuk mendapatkan metode mana yang paling efisien. Dengan demikian, tugas akhir ini ini diharapkan dapat memberikan kontribusi dalam pemanfaatan metode PEFTpada IndoLEM, sekaligus memberikan pemahaman yang lebih baik mengenai efisiensi berbagai teknik \PEFT dalam konteks bahasa Indonesia.
