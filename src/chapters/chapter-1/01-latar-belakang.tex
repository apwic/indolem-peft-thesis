\section{Latar Belakang}
\label{sec:latar-belakang}

Pengolahan bahasa alami (\textit{Natural Language Processing}, NLP) telah menjadi salah satu bidang yang mengalami perkembangan pesat. Kemampuan untuk memahami, menginterpretasi, dan merespons bahasa manusia secara bermakna telah membuka berbagai aplikasi baru yang inovatif. Pengaplikasian bahasa alami mencakup berbagai aspek, mulai dari pemahaman teks (seperti \textit{text classification} dan \textit{sentiment analysis}), hingga generasi bahasa (seperti \textit{machine translation}).

Kemampuan bahasa dari manusia bersifat umum dan fleksibel. Sebaliknya, evaluasi kemampuan pemahaman bahasa (\textit{natural language understanding}, NLU) dari NLP perlu menjalankan berbagai tugas linguistik pada berbagai domain \parencite{glue}. Untuk mengatasi masalah ini, terdapat banyak korpora yang telah diajukan. Salah satunya adalah GLUE (\textit{General Language Understanding Evaluation}) \parencite{glue} dan SuperGLUE \parencite{superglue} untuk mengevaluasi NLU dalam bahasa Inggris. Untuk bahasa Indonesia, terdapat beberapa korpora yang mengikuti jenis evaluasi seperti GLUE, yaitu IndoLEM \parencite{indolem}, IndoNLU \parencite{indonlu}, dan IndoNLG \parencite{indonlg}. IndoLEM dan IndoNLU merupakan tugas evaluasi NLU untuk bahasa Indonesia, sedangkan IndoNLG khusus untuk \textit{Natural Language Genaration} (NLG) dalam bahasa Indonesia.

IndoLEM mempunyai 7 tugas evaluasi yang termasuk ke dalam tiga kategori evaluasi, yaitu \textit{sequence labelling}, \textit{semantics}, dan \textit{discourse coherence} \parencite{indolem}. Dengan tugas evaluasi pada masing-masing kategori ini mencakup berbagai jenis tugas, seperti \textit{classification} dengan tugas \textit{sentiment analysis} dan NER, serta \textit{generation} dengan tugas \textit{summarization (abstractive)} dan \textit{next tweet prediction}. Untuk mencakup kedua kategori dari tugas evaluasi IndoLEM, digunakan NER dan \textit{sentiment analysis} dari kategori \textit{classification} dan \textit{summarization} dari kategori \textit{generation}.

Dalam proses evaluasi IndoLEM, model perlu dilatih pada \textit{dataset} yang tersedia, lalu evaluasi bisa dilakukan dengan membandingkan hasil pelatihannya dengan \textit{benchmark} yang ada. Proses pelatihan pada IndoLEM menggunakan metode \textit{fine-tuning} \parencite{indolem}. Terdapat peluang untuk peningkatan lebih lanjut, terutama dalam hal efisiensi parameter yang digunakan dan waktu pelatihannya. Penggunaan \textit{fine-tuning} pada proses pelatihan, memerlukan sumber daya komputasi yang besar, yang tidak selalu tersedia atau praktis untuk semua pengguna. Salah satu pendekatan yang menjanjikan untuk mengatasi tantangan ini adalah penggunaan teknik \PEFT. PEFT memungkinkan model untuk menyesuaikan dengan tugas-tugas spesifik melalui penyesuaian jumlah parameter yang relatif kecil sehingga mempertahankan sebagian besar parameter model yang telah dilatih sebelumnya \parencite{adapter_houlsby}. Teknik ini tidak hanya dapat mengurangi waktu dan biaya komputasi, tetapi juga memungkinkan penyesuaian model yang lebih cepat dan lebih fleksibel untuk aplikasi spesifik. 

Teknik \PEFT memiliki berbagai variasi, seperti LoRA (\textit{Low-Rank Adaptation}), \textit{Prefix-Tuning}, dan \textit{Adapter}. Teknik-teknik tersebut dianggap sudah mencakup sebagian besar teknik PEFT yang tersedia \parencite{unipelt}. Penelitian yang dilakukan oleh \citeauthor{adapter_houlsby} \parencite{adapter_houlsby} dan \citeauthor{uvpl} \parencite{uvpl} menunjukkan bahwa dengan memperbarui kurang dari 4\% parameter, metode berbasis PEFT dapat mencapai kinerja yang sebanding dengan metode \textit{fine-tuning} penuh. Setiap teknik memiliki karakteristiknya sendiri. Parameter yang dapat dilatih pada PEFT lebih sedikit dibandingkan dengan \textit{fine-tuning}, sehingga membutuhkan komputasi yang lebih sedikit pada proses pelatihannya \parencite{peft_on_plm}. Komputasi yang lebih sedikit ini berpengaruh terhadap waktu pelatihannya, yang membuat waktu pelatihan tersebut lebih cepat dengan parameter yang lebih sedikit. Parameter yang dilatih dan waktu pelatihan menjadi tolak ukur yang perlu dikaji pada tugas akhir ini. Selain itu, hingga saat ini, belum ada penelitian yang memanfaatkan metode PEFT pada tugas evaluasi IndoLEM.

Untuk melakukan evaluasi terhadap setiap metode PEFT, perlu dilakukan pelatihan pada model terlebih dahulu. Model dengan arsitektur Transformer umum digunakan untuk berbagai tugas NLP. Salah satu model yang berbasis arsitektur Transformer salah satunya adalah BERT \parencite{bert}, T5 \parencite{T5}, dan GPT \parencite{gpt}. BERT merupakan model dengan \textit{layer encoder} saja, GPT merupakan model dengan \textit{layer decoder} saja, dan T5 merupakan model dengan \textit{layer encoder} dan juga \textit{decoder}. Model \textit{decoder} yang merupakan model \textit{auto-regressive} seperti GPT mempunyai jumlah parameter yang sangat besar sebanyak 175 miliar \parencite{gpt}, dibanding dengan BERT yang mempunyai jumlah parameter sebanyak 110 juta \parencite{bert} dan T5 yang mempunyai jumlah parameter sebanyak 220 juta \parencite{T5}. Model dengan jumlah parameter yang lebih sedikit akan menggunakan waktu pelatihan yang lebih sedikit juga. Sehingga, model dengan jumlah parameter yang lebih sedikit digunakan untuk melakukan eksperimen terhadap setiap metode PEFT.

Tugas akhir ini  difokuskan pada pemanfaatan berbagai teknik \PEFT pada tugas evaluasi IndoLEM dengan tujuan mengimplementasikan berbagai metode PEFT pada tugas evaluasi IndoLEM. Selain itu, tugas akhir ini  membandingkan kinerja berbagai teknik \PEFT dengan metode \textit{fine-tuning}  untuk mendapatkan metode yang paling efisien. Dengan demikian, tugas akhir ini ini diharapkan dapat memberikan kontribusi dalam pemanfaatan metode PEFT pada IndoLEM, sekaligus memberikan pemahaman yang lebih baik mengenai efisiensi berbagai teknik \PEFT dalam konteks bahasa Indonesia.
