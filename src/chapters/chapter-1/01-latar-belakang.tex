\section{Latar Belakang}
\label{sec:latar-belakang}

Pengolahan bahasa alami (\textit{Natural Language Processing}, NLP) telah menjadi salah satu bidang yang mengalami perkembangan pesat. Kemampuan untuk memahami, menginterpretasi, dan merespons bahasa manusia secara bermakna telah membuka berbagai aplikasi baru yang inovatif. Pengaplikasian bahasa alami mencakup berbagai aspek, mulai dari pemahaman teks (seperti \textit{text classification} dan \textit{sentiment analysis}), hingga generasi bahasa (seperti \textit{machine translation}).

Kemampuan bahasa dari manusia bersifat umum dan fleksibel. Sebaliknya, evaluasi kemampuan pemahaman bahasa (\textit{natural language understanding}, NLU) dari NLP perlu menjalankan berbagai tugas linguistik pada berbagai domain \parencite{glue}. Untuk mengatasi masalah ini, terdapat banyak kakas dan korpora yang telah diajukan. Salah satunya adalah GLUE (\textit{General Language Understanding Evaluation}) \parencite{glue} dan SuperGLUE \parencite{superglue} untuk mengevaluasi NLU dalam bahasa Inggirs. Untuk bahasa Indonesia, terdapat beberapa kakas yang mengikuti jenis evaluasi seperti GLUE, yaitu IndoLEM \parencite{indolem}, IndoNLU \parencite{indonlu}, dan IndoNLG \parencite{indonlg}. IndoLEM dan IndoNLU merupakan kakas evaluasi NLU untuk bahasa Indonesia, sedangkan IndoNLG khusus untuk \textit{Natural Language Genaration} (NLG) untuk bahasa Indonesia.

IndoLEM mempunyai 7 tugas evaluasi yang termasuk ke dalam tiga kategori evaluasi, yaitu \textit{sequence labelling}, \textit{semantics}, dan \textit{discource coherence} \parencite{indolem}. Dengan tugas evaluasi pada masing-masing kategori ini mencakup berbagai jenis tugas, seperti \textit{classification} dengan tugas NER, \textit{generation} dengan tugas \textit{summarization}, dan \textit{next sentence predicition} dengan tugas \textit{next tweet prediction}. Di sisi lain, IndoNLU mempunyai 12 tugas evaluasi dengan fokus utama pada jenis \textit{classification}, yang mencakup \textit{sentiment analysis}, POS \textit{tagging}, NER, \textit{span extraction}, dan \textit{textual entailment} \parencite{indonlu}. Mesikpun IndoNLU mempunyai lebih banyak tugas evaluasi daripada IndoLEM, IndoLEM mempunyai jenis tugas yang lebih bervariatif dibanding IndoNLU yang terfokus pada jenis tugas \textit{classification}. Sehingga, IndoLEM lebih cocok untuk tugas evaluasi yang lebih sederhana.

Dalam proses evaluasi kakas IndoLEM, model perlu dilatih pada \textit{dataset} yang tersedia pada kakas tersebut, lalu evaluasi bisa dilakukan dengan membandingkan hasil pelatihannya dengan \textit{benchmark} yang ada. Proses pelatihan pada IndoLEM menggunakan metode \textit{fine-tuning} \parencite{indolem}. Terdapat peluang untuk peningkatan lebih lanjut, terutama dalam hal efisiensi parameter yang digunakan dan waktu pelatihannya. Penggunaan \textit{fine-tuning} pada proses pelatihan, memerlukan sumber daya komputasi yang besar, yang tidak selalu tersedia atau praktis untuk semua pengguna. Salah satu pendekatan yang menjanjikan untuk mengatasi tantangan ini adalah penggunaan teknik \PEFT. PEFT memungkinkan model untuk menyesuaikan dengan tugas-tugas spesifik dengan mengubah jumlah parameter yang relatif kecil sehingga mempertahankan sebagian besar parameter model yang telah dilatih sebelumnya \parencite{adapter_houlsby}. Teknik ini tidak hanya dapat mengurangi waktu dan biaya komputasi, tetapi juga memungkinkan penyesuaian model yang lebih cepat dan lebih fleksibel untuk aplikasi spesifik. 

Teknik \PEFT memiliki berbagai variasi, seperti LoRA (\textit{Low-Rank Adaptation}), \textit{Prefix-Tuning}, dan \textit{Bottleneck Adapter}. Penelitian yang dilakukan oleh \citeauthor{adapter_houlsby} \parencite{adapter_houlsby} dan \citeauthor{uvpl} \parencite{uvpl} menunjukkan bahwa dengan memperbarui kurang dari 4\% parameter, metode berbasis PEFT dapat mencapai kinerja yang sebanding dengan metode \textit{fine-tuning} penuh. Setiap teknik memiliki karakteristiknya sendiri, dan hingga saat ini, belum banyak penelitian yang secara komprehensif membandingkan kinerja antara teknik-teknik ini, terutama ketika diterapkan pada model IndoBERT. 

Tugas akhir ini  difokuskan pada pemanfaatan berbagai teknik \PEFT pada kakas evaluasi IndoLEM dengan tujuan untuk mengimplementasikan berbagai metode PEFT pada kakas evaluasi IndoLEM. Selain itu, tugas akhir ini  membandingkan kinerja berbagai teknik \PEFT dengan metode \textit{fine-tuning}  untuk mendapatkan metode mana yang paling efisien. Dengan demikian, tugas akhir ini ini diharapkan dapat memberikan kontribusi dalam pemanfaatan metode PEFT pada IndoLEM, sekaligus memberikan pemahaman yang lebih baik mengenai efisiensi berbagai teknik \PEFT dalam konteks bahasa Indonesia.
