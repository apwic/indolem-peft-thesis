% @book{knuth2001art,
%     title={The Art of Computer Programming: Fundamental Algorithms},
%     author={Knuth, D.E.},
%     number={v. 1},
%     isbn={9780201896831},
%     series={The Art of Computer Programming: Fundamental Algorithms},
%     year={2001},
%     publisher={Addison-Wesley}
% }
% @inproceedings{4026885,
%     author={W. Vogels},
%     booktitle={2006 IEEE International Conference on Services Computing (SCC'06)},
%     title={Web Services at Amazon.com},
%     year={2006},
%     pages={xxii-xxii},
%     keywords={Distributed computing;Technological innovation;Web services},
%     doi={10.1109/SCC.2006.116},
%     month={Sept}
% }

@article{nlp,
    title={Speech and Language Processing},
    author={Jurafsky, D. and Martin, J. H.},
    year={2019},
    journal={Stanford University},
    url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{transformers,
    title={Attention Is All You Need},
    author={Vaswani, A. and others},
    year={2017},
    journal={arXiv preprint arXiv:1706.03762},
    url={https://arxiv.org/abs/1706.03762}
}

@article{lora,
    title={Low-Rank Adaptation for Large Language Models},
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen}, 
    year={2021},
    journal={arXiv preprint arXiv:2106.09685},
    url={https://arxiv.org/abs/2106.09685}
}

@article{tinyattention,
    title={Tiny-Attention Adapter: Contexts Are More Important Than the Number of Parameters},
    author={Hongyu Zhao and Hao Tan and Hongyuan Mei}, 
    year={2022},
    journal={arXiv preprint arXiv:2211.01979},
    url={https://arxiv.org/abs/2211.01979}
}

@article{uvpl,
    title={Unified Parameter-Efficient Transfer Learning},
    author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig}, 
    year={2021},
    journal={arXiv preprint arXiv:2110.04366},
    url={https://arxiv.org/abs/2110.04366}
}

@article{bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    journal={arXiv preprint arXiv:1810.04805},
    year={2018},
    url={}
}

@article{indobert,
    title={IndoLEM and IndoBERT: A Benchmark Dataset and Pre-trained Language Model for Indonesian NLP},
    author={Fajri Koto and Afshin Rahimi and Jey Han Lau and Timothy Baldwin},
    journal={arXiv preprint arXiv:2009.05387},
    year={2020},
    url={https://arxiv.org/abs/2011.00677},
}

@article{glue,
    title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
    author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omar Levy and  Samuel R. Bowman},
    journal={arXiv preprint arXiv:1804.07461},
    year={2018},
    url={https://arxiv.org/abs/1804.07461}
}